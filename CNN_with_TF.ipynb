{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_with_TF.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOoWgexFcLO4m2PDhF8cYCr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prajwal270/Tensorflow-Implementation/blob/master/CNN_with_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8qO93hvpQuS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4716484e-e3ea-4dbc-a736-cad3c1c17577"
      },
      "source": [
        "print('CNN with TensorFlow')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN with TensorFlow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3wCG7AS047L",
        "colab_type": "text"
      },
      "source": [
        "## 1st part: Classify MNIST using a simple ANN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBfaYnvNpcg-",
        "colab_type": "text"
      },
      "source": [
        "### Import the MNIST dataset using TensorFlow built-in feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiISAHYIpacE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL-15Y4TprfS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "3379bd91-93ea-4e10-b5e2-4ec5317bd3f5"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-7dc6a806e003>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h2bsjmjqdas",
        "colab_type": "text"
      },
      "source": [
        "You have two basic options when using TensorFlow to run your code:\n",
        "\n",
        "- [Build graphs and run session] Do all the set-up and THEN execute a session to evaluate tensors and run operations (ops) \n",
        "- [Interactive session] create your coding and run on the fly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jjUPoffvQZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moBTpndYqEUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHJddDRpvNf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining our placeholders for input and output value\n",
        "x = tf.placeholder(tf.float32,shape=[None, 784])\n",
        "y = tf.placeholder(tf.float32, shape=[None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO8mI7Q2v2B7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the weights and  bias\n",
        "w = tf.Variable(tf.zeros([784,10], dtype='float32'))\n",
        "b = tf.Variable(tf.zeros([10], dtype='float32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGJwNtZFwQFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL8yIBP_wVaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(init_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOj95wGVwZLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yhat = tf.nn.sigmoid(tf.matmul(x,w) + b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLmH_wOoxTrE",
        "colab_type": "text"
      },
      "source": [
        "### Cost function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ri2Gah2xViw",
        "colab_type": "text"
      },
      "source": [
        "It is a function that is used to minimize the difference between the right answers (labels) and estimated outputs by our Network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9B7IbHWwoAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.reduce_mean(tf.reduce_sum(yhat - tf.log(y), reduction_indices=[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqfqUc64xZ9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2g9iqcFxpoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(100):\n",
        " #Load 50 training examples for each training iteration \n",
        " batch = mnist.train.next_batch(50)\n",
        " train.run(feed_dict={x: batch[0], y: batch[1]}) \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v64Qi04Pyl5j",
        "colab_type": "text"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNNimnw4yWXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74896ec6-eaa3-4db1-ebb2-f70c7e9df293"
      },
      "source": [
        "correct_prediction = tf.equal(tf.argmax(yhat, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "acc = accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}) * 100\n",
        "print(\"The final accuracy for the simple ANN model is: {} % \".format(acc) )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The final accuracy for the simple ANN model is: 10.090000182390213 % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_pGQqaiyuEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close() #finish the session"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIdRd56vy0dT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nCmfLfY1DI0",
        "colab_type": "text"
      },
      "source": [
        "## 2nd part: Deep Learning applied on MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D31jn8n31q9g",
        "colab_type": "text"
      },
      "source": [
        "Architecture of our network is:\n",
        "    \n",
        "- (Input) -> [batch_size, 28, 28, 1]  >> Apply 32 filter of [5x5]\n",
        "- (Convolutional layer 1)  -> [batch_size, 28, 28, 32]\n",
        "- (ReLU 1)  -> [?, 28, 28, 32]\n",
        "- (Max pooling 1) -> [?, 14, 14, 32]\n",
        "- (Convolutional layer 2)  -> [?, 14, 14, 64] \n",
        "- (ReLU 2)  -> [?, 14, 14, 64] \n",
        "- (Max pooling 2)  -> [?, 7, 7, 64] \n",
        "- [fully connected layer 3] -> [1x1024]\n",
        "- [ReLU 3]  -> [1x1024]\n",
        "- [Drop out]  -> [1x1024]\n",
        "- [fully connected layer 4] -> [1x10]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRPWggjq1dHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "6d2447d6-cc8e-4d98-8099-6f36ddd463b0"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS5njHIO2e1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXZMaMB52kTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "3fe6ebd5-a7de-4261-a23d-f8c39838a765"
      },
      "source": [
        "# Getting the data \n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST data\", one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-b1064a8e962a>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrNHPTaY29l1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7003171b-581f-4485-dde1-6803d80944a3"
      },
      "source": [
        "mnist"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f43cfef0fd0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f43cfee9fd0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f43cfef0080>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ifEINj_3A5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write down the general parameter present in the image\n",
        "width = 28\n",
        "height = 28\n",
        "flat = width * height #784\n",
        "class_output = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Map3-5eK4RdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create place holders for inputs and outputs\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[None,784])\n",
        "y = tf.placeholder(tf.float32, shape=[None,10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU0rn7pz4zbw",
        "colab_type": "text"
      },
      "source": [
        "**Converting images of the data set to** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbuy_iY75VOU",
        "colab_type": "text"
      },
      "source": [
        "The input image is 28 pixels by 28 pixels, 1 channel (grayscale). In this case, the first dimension is the batch number of the image, and can be of any size (so we set it to -1). The second and third dimensions are width and height, and the last one is the image channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCrZwcUC4nJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f05104ec-cf84-42ac-d2d0-794315edb3b8"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(784)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjNP_eI5glF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbdbbdd3-488e-4af4-98e6-51fc64cabc3d"
      },
      "source": [
        "x_image = tf.reshape(x,[-1,28,28,1])\n",
        "x_image"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Reshape:0' shape=(?, 28, 28, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMAiIALj54sZ",
        "colab_type": "text"
      },
      "source": [
        "Convolution Layer 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjBRrxtS8Dfg",
        "colab_type": "text"
      },
      "source": [
        "**Defining kernel weight and bias**\n",
        "\n",
        "\n",
        "We define a kernel here. The Size of the filter/kernel is 5x5;  Input channels is 1 (grayscale);  and we need 32 different feature maps (here, 32 feature maps means 32 different filters are applied on each image. So, the output of convolution layer would be 28x28x32). In this step, we create a filter / kernel tensor of shape <code>[filter_height, filter_width, in_channels, out_channels]</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMeOYoOw8BnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w_conv1 = tf.Variable(tf.truncated_normal([5,5,1,32], stddev= 0.1))\n",
        "b_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) # need 32 bias for 32 ouptuts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpYNgb6P5k5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining our first convolution layer\n",
        "convolve1 = tf.nn.conv2d(x_image, w_conv1, strides=[1,1,1,1,], padding='SAME') + b_conv1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "074zfVmc_WS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52cc8f56-6297-4eba-d215-e06f30051b5c"
      },
      "source": [
        "\n",
        "convolve1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add:0' shape=(?, 28, 28, 32) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41rbmNU_-gFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now apply relu activation \n",
        "h_conv1 = tf.nn.relu(convolve1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDOLIbry_Yur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ff1b99f-29ba-49d8-c228-fd076a76aac0"
      },
      "source": [
        "h_conv1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Relu:0' shape=(?, 28, 28, 32) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ_QjpMC-0VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1 = tf.nn.max_pool2d(h_conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') #maxpool 2*2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuOHLLux_arS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36be2d9c-e3f0-420d-faae-950690f82b3d"
      },
      "source": [
        "conv1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'MaxPool2d:0' shape=(?, 14, 14, 32) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YChoMqbZAQoR",
        "colab_type": "text"
      },
      "source": [
        "## Convolution layer 2\n",
        "\n",
        "Here, the input image is [14x14x32], the filter is [5x5x32], we use 64 filters of size [5x5x32], and the output of the convolutional layer would be 64 convolved image, [14x14x64]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6VqwJsK_RYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1))\n",
        "b_conv2 = tf.Variable(tf.constant(0.1, shape=[64])) #need 64 biases for 64 outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12AMCBJMAZwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convolve2 = tf.nn.conv2d(conv1, W_conv2,strides=[1,1,1,1], padding='SAME') + b_conv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DLJ8wDFBHL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9d59c86-7a1a-43bd-b077-178df750b6c7"
      },
      "source": [
        "convolve2"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add_1:0' shape=(?, 14, 14, 64) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z0Xoc_EAuSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h_conv2 = tf.nn.relu(convolve2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guKuPkevBKlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05593df7-3400-4002-ec34-1e59b5f7555e"
      },
      "source": [
        "h_conv2"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Relu_1:0' shape=(?, 14, 14, 64) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ognm39qAzoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv2 = tf.nn.max_pool2d(h_conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKLd1OxDBMwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88fc4734-dcc6-4251-fe86-48957c077ee4"
      },
      "source": [
        "conv2"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'MaxPool2d_1:0' shape=(?, 7, 7, 64) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_0Vvbn-BT0u",
        "colab_type": "text"
      },
      "source": [
        "Second layer completed. So, what is the output of the second layer, layer2?\n",
        "\n",
        "it is 64 matrix of [7x7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxGy47QlBWvA",
        "colab_type": "text"
      },
      "source": [
        "**Fully Conneted Layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50hNAJl4B_uY",
        "colab_type": "text"
      },
      "source": [
        "Each matrix [7x7] will be converted to a matrix of [49x1], and then all of the 64 matrix will be connected, which make an array of size [3136x1]. We will connect it into another layer of size [1024x1]. So, the weight between these 2 layers will be [3136x1024]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NJ6xWlPCkoz",
        "colab_type": "text"
      },
      "source": [
        "Flattening Second Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjM8p1zdCjvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer2 = tf.reshape(conv2 ,[-1, 7*7*64])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcuhYFszn_Ig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea4e3936-613f-414e-f095-914bc4d3754a"
      },
      "source": [
        "layer2"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Reshape_1:0' shape=(?, 3136) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXtHWlEcnwUu",
        "colab_type": "text"
      },
      "source": [
        "**Weights and Biases between layer 2 and 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkaTH29Cn408",
        "colab_type": "text"
      },
      "source": [
        "Composition of the feature map from the last layer (7x7) multiplied by the number of feature maps (64); 1027 outputs to Softmax layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdBlozZvBTi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w_fc1 = tf.Variable(tf.truncated_normal([7*7*64, 1024], stddev=0.1))\n",
        "b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024])) #need 1024 bias for 1024 outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oacAPAfTBE3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc1 = tf.matmul(layer2,w_fc1,) + b_fc1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwNgoEFApqmF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2aa1fb2-052f-4309-81cf-bcacc70117bb"
      },
      "source": [
        "fc1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add_2:0' shape=(?, 1024) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gKesiPFphBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "113481d1-8510-4075-8d7c-c8be60f13f70"
      },
      "source": [
        "hfc1 = tf.nn.relu(fc1)\n",
        "hfc1"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Relu_3:0' shape=(?, 1024) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlEpdE81p2e0",
        "colab_type": "text"
      },
      "source": [
        "Third Layer completed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXH-11KLqq8c",
        "colab_type": "text"
      },
      "source": [
        "**Dropout Layer Optional phase for reudcing overfitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlc52ySKq5rc",
        "colab_type": "text"
      },
      "source": [
        "It is a phase where the network \"forget\" some features. At each training step in a mini-batch, some units get switched off randomly so that it will not interact with the network. That is, it weights cannot be updated, nor affect the learning of the other network nodes. This can be very useful for very large neural networks to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH7Wlfcspp9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "1f4d4cae-3021-46a3-de1d-14e8ee3c4899"
      },
      "source": [
        "keep_prob = tf.placeholder(tf.float32)\n",
        "layer_drop = tf.nn.dropout(hfc1,keep_prob)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-55d6cfd8ed5e>:2: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoOa_harf4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8250cc70-bf37-4b6a-d173-4a0ddc926852"
      },
      "source": [
        "layer_drop"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dropout/mul_1:0' shape=(?, 1024) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc1Hl2Zrr3On",
        "colab_type": "text"
      },
      "source": [
        "**Last Layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gttaHO1r83k",
        "colab_type": "text"
      },
      "source": [
        "In last layer, CNN takes the high-level filtered images and translate them into votes using softmax. Input channels: 1024 (neurons from the 3rd Layer); 10 output features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8PZzr7ir8Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w_fc2 = tf.Variable(tf.truncated_normal([1024,10], stddev=0.1)) # 1024 neuron\n",
        "b_fc2 = tf.Variable(tf.constant(0.1, shape=[10])) # 10 output class "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN8c0NmCrokO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_layer = tf.nn.softmax(tf.matmul(layer_drop, w_fc2) + b_fc2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZUgz7ODszUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38053780-0bc9-4976-ad94-ad184c3cf676"
      },
      "source": [
        "last_layer"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Softmax:0' shape=(?, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49MMNe0ntaRk",
        "colab_type": "text"
      },
      "source": [
        "**Now Define our Loss function and optimizer and then train the neural net**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaFPp96Mts5p",
        "colab_type": "text"
      },
      "source": [
        "we will be using cross_entropy as our loss function  to measure the error at softmax layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws-KnWWis0Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.reduce_mean(tf.square(y * tf.log(last_layer)), reduction_indices=[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiayAD4hu4-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tN7fY_jvPNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e110bc76-75a3-4a45-e3c8-74e00ce864b6"
      },
      "source": [
        "train"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Operation 'Adam' type=NoOp>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2ei7OaQve3e",
        "colab_type": "text"
      },
      "source": [
        "**Define Prediction**\n",
        "\n",
        "how many of the cases in a mini-batch has been classified correctly?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjuiSwBzvdLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction = tf.equal(tf.argmax(last_layer, 1), tf.argmax(y, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptrxJWMBvuuH",
        "colab_type": "text"
      },
      "source": [
        "**Define accuracy**\n",
        "\n",
        "It makes more sense to report accuracy using average of correct cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykwCVp4QwrNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5lN0iGQvnts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now its the time to Train , to do so first intialize the variables\n",
        "init_op = tf.global_variables_initializer()\n",
        "sess.run(init_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXOygJW2wLi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "5e519f54-5bd6-464c-ec7f-df8a50358fd5"
      },
      "source": [
        "for i in range(1000):\n",
        "  batch = mnist.train.next_batch(50)\n",
        "  if i %100 ==0 :\n",
        "    acc = accuracy.eval(feed_dict={x: batch[0], y : batch[1], keep_prob:1.0})\n",
        "    print(\"step %d, training accuracy %g\"%(i, float(acc)))\n",
        "  train.run(feed_dict={x:batch[0], y: batch[1], keep_prob:0.5})  \n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training accuracy 0.04\n",
            "step 100, training accuracy 0.7\n",
            "step 200, training accuracy 0.82\n",
            "step 300, training accuracy 0.9\n",
            "step 400, training accuracy 0.92\n",
            "step 500, training accuracy 0.94\n",
            "step 600, training accuracy 0.9\n",
            "step 700, training accuracy 0.94\n",
            "step 800, training accuracy 0.94\n",
            "step 900, training accuracy 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQfd1fBBxzU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}